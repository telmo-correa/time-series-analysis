{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Parameter Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7.1**. From a series of length 100, we have computed $r_1 = 0.8$, $r_2 = 0.5$, $r_3 = 0.4$, $\\overline{Y} = 2$, and a sample variance of 5. If we assume that an AR(2) model with a constant term is appropriate, how can we get (simple) estimates of $\\phi_1$, $\\phi_2$, $\\theta_0$, and $\\sigma_e^2$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**.  Equation (7.1.2) gives us, for the AR(2) model, the estimates\n",
    "\n",
    "$$ \\hat{\\phi}_1 = \\frac{r_1(1 - r_2)}{1 - r_1^2} \\quad \\text{and} \\quad \\hat{\\phi}_2 = \\frac{r_2 - r_1^2}{1 - r_1^2} $$\n",
    "\n",
    "Then,\n",
    "\n",
    "$$ \\hat{\\theta}_0 = \\overline{Y}(1 - \\hat{\\phi}_1 - \\hat{\\phi}_2) $$\n",
    "\n",
    "and from Equation (7.1.8)\n",
    "\n",
    "$$ \\hat{\\sigma}_e^2 = s^2(1 - \\hat{\\phi}_1 r_1 - \\hat{\\phi}_2 r_2) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1, r2, r3 = 0.8, 0.5, 0.4\n",
    "Ybar = 2\n",
    "s2 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi1 = r1 * (1 - r2) / (1 - r1**2)\n",
    "phi2 = (r2 - r1**2) / (1 - r1**2)\n",
    "theta0 = Ybar * (1 - phi1 - phi2)\n",
    "se = s2 * (1 - phi1 * r1 - phi2 * r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1111111111111116, -0.3888888888888894, 0.5555555555555556, 1.527777777777777)\n"
     ]
    }
   ],
   "source": [
    "print((phi1, phi2, theta0, se))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7.2**.  Assuming that the following data arise from a stationary process, calculate method-of-moments estimates of $\\mu$, $\\gamma_0$, and $\\rho_1$: 6, 5, 4, 6, 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array([6, 5, 4, 6, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5.0, 1.0, -0.5)\n"
     ]
    }
   ],
   "source": [
    "mu_hat = np.mean(Y)\n",
    "gamma_0_hat = np.sum((Y - mu_hat)**2) / (len(Y) - 1)\n",
    "rho_1 = (Y[:-1] - mu_hat)@(Y[1:] - mu_hat) / (len(Y) - 1)\n",
    "\n",
    "print((mu_hat, gamma_0_hat, rho_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7.3**. If $\\{Y_t\\}$ satisfies an AR(1) model with $\\phi$ of about 0.7, how long of a series do we need to estimate $\\phi = \\rho_1$ with 95% confidence that our estimation error is no more than $\\pm 0.1$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**.  For the AR(1) model, the large sample standard error of $\\hat{\\phi}$ is $\\sqrt{(1 - \\phi^2) / n}$.  For a degree of confidence of $1 - \\alpha$, we need\n",
    "\n",
    "$$ \\Phi(1 - \\alpha/2) \\sqrt{\\frac{1 - \\phi^2}{n}} \\leq 0.1 $$\n",
    "\n",
    "or\n",
    "\n",
    "$$ (1 - \\phi^2) \\left( \\frac{\\Phi(1 - \\alpha/2)}{0.1} \\right)^2 \\leq n $$\n",
    "\n",
    "where $\\Phi$ is the CDF of the standard normal.  Replacing in $\\alpha = 0.05$ and $\\phi = 0.7$, the bound becomes $n \\geq 196$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7.4** Consider an MA(1) process for which it is *known* that the process mean is zero.  Based on a series of length $n = 3$, we observe $Y_1 = 0$, $Y_2 = −1$, and $Y_3 = 1/2$.\n",
    "\n",
    "**(a)** Show that the conditional least-squares estimate of $\\theta$ is $1/2$.\n",
    "\n",
    "**(b)** Find an estimate of the noise variance. (Hint: Iterative methods are not needed in this simple case.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**  From Equation (7.2.14),\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "e_1 &=& Y_1 \\\\\n",
    "e_2 &=& Y_2 + \\theta e_1 \\\\\n",
    "e_3 &=& Y_3 + \\theta e_2 \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "and so $e_1 = Y_1 = 0$, $e_2 = Y_2 + \\theta e_1 = -1$, and $e_3 = Y_3 + \\theta e_2 = 1/2 - \\theta$.  The conditional sum-of-squares is\n",
    "\n",
    "$$ S_c(\\theta) = \\sum_i e_i^2 = 0^2 + 1^2 + \\left( \\frac{1}{2} - \\theta \\right)^2 $$\n",
    "\n",
    "which is minimized at $\\theta = 1/2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**  From Equation (7.1.9),\n",
    "\n",
    "$$ \\hat{\\sigma}_e^2(\\theta) = \\frac{s^2}{1 + \\theta^2} = \\frac{1}{1 + \\theta^2} \\left( \\frac{1}{n - 1} S_c(\\theta) \\right) $$\n",
    "\n",
    "which, for $\\theta = 1/2$, has value $\\sigma_e^2 = 0.4$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7.5**.  Given the data $Y_1 = 10$, $Y_2 = 9$, and $Y_3 = 9.5$, we wish to fit an IMA(1,1) model without a constant term.\n",
    "\n",
    "**(a)** Find the conditional least squares estimate of $\\theta$. (Hint: Do Exercise 7.4 first.)\n",
    "\n",
    "**(b)** Estimate $\\sigma_e^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**  We have $\\nabla Y_1 = -1$ and $\\nabla Y_2 = 0.5$.  Fitting the MA(1) model on $\\nabla Y_t$ with a zero mean,\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "e_1 &=& \\nabla Y_1 \\\\\n",
    "e_2 &=& \\nabla Y_2 + \\theta e_1\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "and so $e_1 = \\nabla Y_1 = -1$ and $e_2 = \\nabla Y_2 + \\theta e_1 = 0.5 - \\theta$.  The conditional sum-of-squares is\n",
    "\n",
    "$$ S_c(\\theta) = \\sum_i e_i^2 = (-1)^2 + (0.5 - \\theta)^2 $$\n",
    "\n",
    "which is minimized at $\\theta = 0.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**  From Equation (7.1.9),\n",
    "\n",
    "$$ \\hat{\\sigma}_e^2(\\theta) = \\frac{s^2}{1 + \\theta^2} = \\frac{1}{1 + \\theta^2} \\left( \\frac{1}{n - 1} S_c(\\theta) \\right) $$\n",
    "\n",
    "which, for $\\theta = 0.5$, has value $\\hat{\\sigma}_e^2 = 0.8$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7.6**.  Consider two different parameterizations of the AR(1) process with nonzero mean:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lrcl}\n",
    "\\text{Model I:}  &  Y_t − \\mu &=& \\phi(Y_{t−1} − \\mu) + e_t \\\\\n",
    "\\text{Model II:} &         Y_t &=& \\phi Y_{t−1} + \\theta_0 + e_t \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "We want to estimate $\\phi$ and $\\mu$ or $\\phi$ and $\\theta_0$ using conditional least squares conditional on $Y_1$. Show that with Model I we are led to solve nonlinear equations to obtain the estimates, while with Model II we need only solve linear equations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**.  We can express Model I as\n",
    "\n",
    "$$ Y_t = \\phi Y_{t-1} + \\mu (1 - \\phi) + e_t $$\n",
    "\n",
    "which is non-linear on $\\mu$ and $\\phi$, and so setting the partial derivatives of $S_c(\\mu, \\phi) = \\sum_t (e_t)^2$ to zero will not be linear equations.\n",
    "\n",
    "On the other hand, model II is linear on $\\phi$ and $\\theta_0$, so setting the partial derivatives of $S_c(\\mu, \\phi) = \\sum_t (e_t)^2$ to zero produces linear equations on $\\phi$ and $\\theta_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7.7**. Verify Equation (7.1.4) on page 150."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**.  Equation (7.1.4) states that, for the MA(1) process, the root satisfying the invertibility condition $|\\theta| < 1$ has estimate\n",
    "\n",
    "$$ \\hat{\\theta} = \\frac{-1 + \\sqrt{1 - 4r_1^2}}{2r_1} $$\n",
    "\n",
    "From Equation (4.2.2), we have\n",
    "\n",
    "$$ r_1 = - \\frac{\\hat{\\theta}}{1 + \\hat{\\theta}^2} $$\n",
    "\n",
    "which can be written as the second-degree equation\n",
    "\n",
    "$$ \\hat{\\theta}^2 r_1 + \\hat{\\theta} + r_1 = 0 $$\n",
    "\n",
    "Its roots are\n",
    "\n",
    "$$ \\frac{-1 \\pm \\sqrt{1 - 4 r_1^2}}{2r_1} $$\n",
    "\n",
    "The product of the roots is 1, so only one of them can have absolute value less than or equal to 1.  We also have\n",
    "\n",
    "$$ \\left|\\frac{-1 + \\sqrt{1 - 4r_1^2}}{2r_1} \\right| < \\frac{1}{| 2 r_1 |} \\leq 1 $$\n",
    "\n",
    "and so the given root should be the selected estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7.8**.  Consider an ARMA(1,1) model with $\\phi = 0.5$ and $\\theta = 0.45$.\n",
    "\n",
    "**(a)** For $n = 48$, evaluate the variances and correlation of the maximum likelihood estimators of $\\phi$ and $\\theta$ using Equations (7.4.13) on page 161. Comment on the results.\n",
    "\n",
    "**(b)** Repeat part (a) but now with $n = 120$. Comment on the new results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**  Equations (7.4.13) state that:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "\\text{Var}[\\hat{\\phi}] &\\approx& \\left[ \\frac{1 - \\phi^2}{n} \\right] \\left[ \\frac{1 - \\phi \\theta}{\\phi - \\theta}\\right]^2 \\\\\n",
    "\\text{Var}[\\hat{\\theta}] &\\approx& \\left[ \\frac{1 - \\theta^2}{n} \\right] \\left[ \\frac{1 - \\phi \\theta}{\\phi - \\theta}\\right]^2 \\\\\n",
    "\\text{Corr}[\\hat{\\phi}, \\hat{\\theta}] &\\approx& \\frac{\\sqrt{(1 - \\phi^2)(1 - \\theta^2)}}{1 - \\phi \\theta}\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.7539062500000018, 3.9916536458333347, 0.9979166644037433)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi = 0.5\n",
    "theta = 0.45\n",
    "n = 48\n",
    "\n",
    "var_phi_hat = ((1 - phi**2)/n) * ((1 - phi * theta) / (theta - phi))**2\n",
    "var_theta_hat = ((1 - theta**2)/n) * ((1 - phi * theta) / (theta - phi))**2\n",
    "corr_phi_hat_theta_hat = np.sqrt((1 - phi**2) * (1 - theta**2)) / (1 - phi * theta)\n",
    "\n",
    "var_phi_hat, var_theta_hat, corr_phi_hat_theta_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables are close to each other, which causes the variances to be high and the estimates to be highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.5015625000000008, 1.596661458333334, 0.9979166644037433)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi = 0.5\n",
    "theta = 0.45\n",
    "n = 120\n",
    "\n",
    "var_phi_hat = ((1 - phi**2)/n) * ((1 - phi * theta) / (theta - phi))**2\n",
    "var_theta_hat = ((1 - theta**2)/n) * ((1 - phi * theta) / (theta - phi))**2\n",
    "corr_phi_hat_theta_hat = np.sqrt((1 - phi**2) * (1 - theta**2)) / (1 - phi * theta)\n",
    "\n",
    "var_phi_hat, var_theta_hat, corr_phi_hat_theta_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variances of the estimates go down with $n$, but the correlation does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7.9**. Simulate an MA(1) series with $\\theta = 0.8$ and $n = 48$.\n",
    "\n",
    "**(a)** Find the method-of-moments estimate of $\\theta$.\n",
    "\n",
    "**(b)** Find the conditional least squares estimate of $\\theta$ and compare it with part (a).\n",
    "\n",
    "**(c)** Find the maximum likelihood estimate of $\\theta$ and compare it with parts (a) and (b).\n",
    "\n",
    "**(d)** Repeat parts (a), (b), and (c) with a new simulated series using the same parameters and same sample size. Compare your results with your results from the first simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "def generate_arima(phi=[], d=0, theta=[], n=100):\n",
    "    ar = np.r_[1, -np.array(phi)]\n",
    "    ma = np.r_[1, -np.array(theta)]\n",
    "    Y = ArmaProcess(ar, ma).generate_sample(nsample=n)\n",
    "    for i in range(d):\n",
    "        Y = np.cumsum(Y)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "Y = generate_arima(theta=[0.8], n=48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "def estimate_ma1_mom(x):\n",
    "    r = acf(Y, fft=False, nlags=1)[1]\n",
    "    if np.abs(r) < 0.5:\n",
    "        return (-1 + np.sqrt(1 - 4 * r**2))/(2*r)\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6403760599885285"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_ma1_mom(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.75869964])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARIMA(Y, order=(0, 0, 1)).fit(method='css').maparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our convention for the sign of $\\theta$, this estimate is $\\theta=0.759$, which is a better estimate than in part (a)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.99986536])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARIMA(Y, order=(0, 0, 1)).fit(method='mle').maparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our convention for the sign of $\\theta$, this estimate is very close to $\\theta=1$, which is concerning as it does not provide invertibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "[-0.99999996]\n",
      "[-0.99995614]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "Y = generate_arima(theta=[0.8], n=48)\n",
    "print(estimate_ma1_mom(Y))\n",
    "print(ARIMA(Y, order=(0, 0, 1)).fit(method='css').maparams)\n",
    "print(ARIMA(Y, order=(0, 0, 1)).fit(method='mle').maparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, the method of moments failed to provide a valid estimate, while both the CSS and MLE methods provided an estimate very close to 1; results are worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7.10**.  Simulate an MA(1) series with $\\theta = −0.6$ and $n = 36$.\n",
    "\n",
    "**(a)** Find the method-of-moments estimate of $\\theta$.\n",
    "\n",
    "**(b)** Find the conditional least squares estimate of $\\theta$ and compare it with part (a).\n",
    "\n",
    "**(c)** Find the maximum likelihood estimate of $\\theta$ and compare it with parts (a) and (b).\n",
    "\n",
    "**(d)** Repeat parts (a), (b), and (c) with a new simulated series using the same parameters and same sample size. Compare your results with your results from the first simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1000)\n",
    "Y = generate_arima(theta=[-0.6], n=36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.36076887498825894"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_ma1_mom(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4716205])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARIMA(Y, order=(0, 0, 1)).fit(method='css').maparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our convention for the sign of $\\theta$, this estimate is very close to $\\theta=1$, which is concerning as it does not provide invertibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48058205])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARIMA(Y, order=(0, 0, 1)).fit(method='mle').maparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our convention for the sign of $\\theta$, this estimate is very close to $\\theta=1$, which is concerning as it does not provide invertibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "[0.66970618]\n",
      "[0.64767655]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1001)\n",
    "Y = generate_arima(theta=[-0.6], n=36)\n",
    "print(estimate_ma1_mom(Y))\n",
    "print(ARIMA(Y, order=(0, 0, 1)).fit(method='css').maparams)\n",
    "print(ARIMA(Y, order=(0, 0, 1)).fit(method='mle').maparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, method-of-moments failed to provide an estimate, while both CSS and ML provided estimates closer to the real value of $\\theta = -0.6$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
